namespace inference {
    [Throws=SemanticError]
    Semantic init_semantic(sequence<u8> model, sequence<u8> tokenizer_data);
    [Throws=SemanticError]
    Semantic init_semantic_with_path([ByRef] string model_path, [ByRef] string tokenizer_path);
    Similarity get_cosine_similarity();
};

[Custom]
typedef sequence<f32> Embedding;

[Trait]
interface Similarity {
    float similarity_score([ByRef] Embedding set1, [ByRef] Embedding set2);
};

dictionary Metadata {
    record<string, string> metadata;
};

dictionary Document {
    string id;
    Metadata metadata;
    string text;
    Embedding vector;
};

[Error]
enum SemanticError {
  "TokenizeEncodeError",
  "TokenizeEncodeByteError",
  "ShapeError",
  "InitSessionBuilder",
  "InitSessionOptimization",
  "InitBuildOrtEnv",
  "InitSessionThreads",
  "InitModelReadError",
  "InitTokenizerReadError"
};

interface Semantic {
    [Throws=SemanticError]
    Embedding embed([ByRef] string sequence);
};

dictionary DocumentMatch {
    float score;
    string embedding_id;
    Embedding embedding;
    Document embedded;
};

interface InMemoryEmbeddingStore {
    [Name=new]
    constructor();

    string add(string id, Embedding embedding, Document document);
    sequence<string> add_all(sequence<Embedding> embeddings, sequence<Document> documents);
    sequence<DocumentMatch> find_relevant(Embedding reference_embedding, i8 max_results, float min_score);
};

